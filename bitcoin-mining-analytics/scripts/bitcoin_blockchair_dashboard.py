# scripts/bitcoin_blockchair_dashboard.py
import asyncio
import aiohttp
import json
import sys
import os
from datetime import datetime
import logging

# Adicionar diretÃ³rio pai ao path para imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Tentar importar o coletor modular
try:
    from src.data.collectors.blockchain_collector import get_primary_metrics, collect_blockchain_data
    COLLECTOR_AVAILABLE = True
    print("âœ… Coletor modular carregado com sucesso")
except ImportError as e:
    print(f"âš ï¸ Coletor modular nÃ£o disponÃ­vel: {e}")
    COLLECTOR_AVAILABLE = False

# Tentar importar o gerenciador de banco
try:
    from database.duckdb_manager import DuckDBManager
    DB_AVAILABLE = True
    print("âœ… Gerenciador de banco DuckDB carregado")
except ImportError as e:
    print(f"âš ï¸ Gerenciador de banco nÃ£o disponÃ­vel: {e}")
    DB_AVAILABLE = False

class BitcoinBlockchairDashboard:
    """
    Dashboard principal para coleta e anÃ¡lise de dados Bitcoin
    VersÃ£o com DuckDBManager totalmente integrado
    """

    def __init__(self, use_modular_collector=True, enable_database=True):
        self.base_url = "https://api.blockchair.com/bitcoin/stats"
        self.data = None
        self.use_modular_collector = use_modular_collector and COLLECTOR_AVAILABLE
        self.enable_database = enable_database and DB_AVAILABLE
        self.setup_directories()
        self.setup_logging()

        # âœ… INICIALIZAÃ‡ÃƒO CORRETA DO BANCO
        if self.enable_database:
            try:
                self.db_manager = DuckDBManager()
                self.logger.info("ğŸ—„ï¸ PersistÃªncia em banco ativada - DuckDBManager inicializado")
            except Exception as e:
                self.logger.error(f"âŒ Falha ao inicializar DuckDBManager: {e}")
                self.enable_database = False
                self.db_manager = None
        else:
            self.db_manager = None
            self.logger.info("ğŸ“„ PersistÃªncia em banco desativada")

        if self.use_modular_collector:
            self.logger.info("ğŸš€ Coletor modular ativado")
        else:
            self.logger.info("ğŸ”„ Usando coletor direto (fallback)")

    def setup_directories(self):
        """Cria diretÃ³rios necessÃ¡rios"""
        directories = [
            'data/raw/blockchain',
            'data/backups',
            'logs',
            'results/financial_analysis',
            'exports'
        ]

        for directory in directories:
            os.makedirs(directory, exist_ok=True)
            print(f"ğŸ“ DiretÃ³rio criado/verificado: {directory}")

    def setup_logging(self):
        """Configura o sistema de logging"""
        log_file = 'logs/dashboard.log'

        # Garantir que o diretÃ³rio de logs existe
        os.makedirs('logs', exist_ok=True)

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler(log_file, encoding='utf-8')
            ]
        )
        self.logger = logging.getLogger(__name__)
        self.logger.info("âœ… Sistema de logging configurado")

    async def fetch_blockchain_data_modular(self):
        """
        Coleta dados usando o coletor modular
        """
        try:
            self.logger.info("ğŸ”„ Usando coletor modular para coleta de dados...")
            data = await get_primary_metrics()

            if data and len(data) > 0:
                self.logger.info(f"âœ… Coletor modular: {len(data)} campos coletados")
                return data
            else:
                self.logger.warning("âš ï¸ Coletor modular retornou dados vazios")
                return None

        except Exception as e:
            self.logger.error(f"âŒ Erro no coletor modular: {e}")
            return None

    async def fetch_blockchain_data_direct(self):
        """
        Coleta dados diretamente da API Blockchair (fallback)
        """
        async with aiohttp.ClientSession() as session:
            try:
                self.logger.info(f"ğŸŒ Conectando diretamente: {self.base_url}")
                print(f"ğŸŒ Conectando: {self.base_url}")

                async with session.get(self.base_url, timeout=30) as response:
                    if response.status == 200:
                        data = await response.json()
                        self.logger.info("âœ… Dados coletados com sucesso via API direta")
                        print("âœ… Dados coletados com sucesso")
                        return data['data']
                    else:
                        error_msg = f"âŒ Erro na API direta: Status {response.status}"
                        self.logger.error(error_msg)
                        print(error_msg)
                        return None

            except asyncio.TimeoutError:
                error_msg = "â° Timeout na requisiÃ§Ã£o direta"
                self.logger.error(error_msg)
                print(error_msg)
                return None
            except Exception as e:
                error_msg = f"âŒ Erro na requisiÃ§Ã£o direta: {e}"
                self.logger.error(error_msg)
                print(error_msg)
                return None

    async def fetch_blockchain_data(self):
        """
        Coleta dados - usa coletor modular se disponÃ­vel, fallback para direto
        """
        if self.use_modular_collector:
            modular_data = await self.fetch_blockchain_data_modular()
            if modular_data:
                return modular_data
            else:
                self.logger.warning("ğŸ” Coletor modular falhou, tentando mÃ©todo direto...")

        # Fallback para mÃ©todo direto
        return await self.fetch_blockchain_data_direct()

    def process_hashrate(self, hashrate_str):
        """
        Processa e converte o hash rate para diferentes unidades
        """
        try:
            hashrate_hs = int(hashrate_str)

            conversions = {
                'hash/s': hashrate_hs,
                'kilohash/s': hashrate_hs / 1e3,
                'megahash/s': hashrate_hs / 1e6,
                'gigahash/s': hashrate_hs / 1e9,
                'terahash/s': hashrate_hs / 1e12,
                'petahash/s': hashrate_hs / 1e15,
                'exahash/s': hashrate_hs / 1e18
            }

            return conversions

        except (ValueError, TypeError) as e:
            self.logger.error(f"âŒ Erro ao processar hash rate: {e}")
            print(f"âŒ Erro ao processar hash rate: {e}")
            return {}

    def calculate_mining_metrics(self, data):
        """
        Calcula mÃ©tricas de mineraÃ§Ã£o baseadas nos dados da rede
        """
        if not data:
            return {}

        try:
            # Hash rate em EH/s para cÃ¡lculos
            hashrate_ehs = self.process_hashrate(data.get('hashrate_24h', '0')).get('exahash/s', 0)
            difficulty = data.get('difficulty', 0)
            block_reward = 6.25  # BTC
            btc_price = data.get('market_price_usd', 0)

            # CÃ¡lculos bÃ¡sicos de mineraÃ§Ã£o
            daily_blocks = data.get('blocks_24h', 144)
            network_hashrate_th = hashrate_ehs * 1e6  # Converter EH/s para TH/s

            # Receita diÃ¡ria da rede (aproximada)
            daily_network_revenue = daily_blocks * block_reward * btc_price

            # Hash price (USD per TH/s per day)
            hash_price = daily_network_revenue / network_hashrate_th if network_hashrate_th > 0 else 0

            metrics = {
                'hashrate_ehs': hashrate_ehs,
                'hashrate_phs': hashrate_ehs * 1000,  # PH/s
                'daily_blocks': daily_blocks,
                'block_time_actual': (24 * 3600) / daily_blocks if daily_blocks > 0 else 600,
                'daily_network_revenue_usd': daily_network_revenue,
                'hash_price_usd_per_th_per_day': hash_price,
                'network_efficiency_j_per_th': 30,  # Estimativa conservadora
                'estimated_daily_energy_consumption_gwh': (hashrate_ehs * 1e6 * 30 * 24) / 1e9,  # GWh corrigido
            }

            return metrics

        except Exception as e:
            self.logger.error(f"âŒ Erro ao calcular mÃ©tricas de mineraÃ§Ã£o: {e}")
            print(f"âŒ Erro ao calcular mÃ©tricas de mineraÃ§Ã£o: {e}")
            return {}

    def analyze_profitability(self, data, mining_metrics):
        """
        Analisa a lucratividade bÃ¡sica da mineraÃ§Ã£o
        """
        if not data or not mining_metrics:
            return {}

        try:
            btc_price = data.get('market_price_usd', 0)
            hash_price = mining_metrics.get('hash_price_usd_per_th_per_day', 0)

            # ParÃ¢metros de um minerador S19 XP (140 TH/s, 3010W)
            miner_hashrate_th = 140
            miner_power_consumption_w = 3010
            energy_cost_per_kwh = 0.08  # USD

            # CÃ¡lculos de lucratividade
            daily_revenue = hash_price * miner_hashrate_th
            daily_energy_cost = (miner_power_consumption_w * 24 / 1000) * energy_cost_per_kwh
            daily_profit = daily_revenue - daily_energy_cost

            # ROI bÃ¡sico (considerando custo do hardware de $4500)
            hardware_cost = 4500
            roi_days = hardware_cost / daily_profit if daily_profit > 0 else float('inf')

            profitability = {
                'miner_model': 'Antminer S19 XP',
                'miner_hashrate_th': miner_hashrate_th,
                'miner_power_w': miner_power_consumption_w,
                'energy_cost_per_kwh': energy_cost_per_kwh,
                'daily_revenue_usd': daily_revenue,
                'daily_energy_cost_usd': daily_energy_cost,
                'daily_profit_usd': daily_profit,
                'profit_margin_percentage': (daily_profit / daily_revenue * 100) if daily_revenue > 0 else 0,
                'roi_days': roi_days,
                'break_even_days': roi_days,
                'monthly_profit_usd': daily_profit * 30,
                'annual_profit_usd': daily_profit * 365,
            }

            return profitability

        except Exception as e:
            self.logger.error(f"âŒ Erro ao analisar lucratividade: {e}")
            print(f"âŒ Erro ao analisar lucratividade: {e}")
            return {}

    def save_to_database(self, data, mining_metrics, profitability):
        """
        âœ… VERSÃƒO CORRIGIDA - Salva dados no banco DuckDB
        """
        if not self.enable_database or not self.db_manager:
            self.logger.info("ğŸ“„ PersistÃªncia em banco desativada")
            return False

        try:
            # Determinar fonte dos dados
            source = "modular" if self.use_modular_collector else "direct"

            self.logger.info(f"ğŸ’¾ Iniciando salvamento no banco - Fonte: {source}")

            # âœ… PREPARAR DADOS PARA A REDE (schema simplificado)
            network_data = {
                'blocks_24h': data.get('blocks_24h', 0),
                'transactions_24h': data.get('transactions_24h', 0),
                'hashrate_24h': data.get('hashrate_24h', 0),
                'difficulty': data.get('difficulty', 0),
                'market_price_usd': data.get('market_price_usd', 0),
                'mempool_transactions': data.get('mempool_transactions', 0),
                'average_transaction_fee_usd_24h': data.get('average_transaction_fee_usd_24h', 0),
                'nodes': data.get('nodes', 0),
                'blockchain_size': data.get('blockchain_size', 0)
            }

            # âœ… SALVAR MÃ‰TRICAS DE REDE (agora retorna ID)
            network_id = self.db_manager.save_network_metrics(network_data, source)

            if not network_id:
                self.logger.error("âŒ Falha crÃ­tica ao salvar mÃ©tricas de rede")
                return False

            self.logger.info(f"âœ… MÃ©tricas de rede salvas - ID: {network_id}")

            # âœ… SALVAR ANÃLISE DE LUCROTIVIDADE
            if profitability:
                profitability_success = self.db_manager.save_profitability_analysis(
                    profitability,
                    network_id
                )
                if profitability_success:
                    self.logger.info("âœ… AnÃ¡lise de lucratividade salva no banco")
                else:
                    self.logger.warning("âš ï¸ Falha ao salvar anÃ¡lise de lucratividade")

            # âœ… SALVAR SNAPSHOT COMPLETO
            snapshot_data = {
                'timestamp': datetime.now().isoformat(),
                'source': source,
                'metadata': {
                    'success_sources': [source],
                    'network_metrics_id': network_id
                },
                'network_data': data,
                'mining_metrics': mining_metrics,
                'profitability_analysis': profitability
            }

            snapshot_success = self.db_manager.save_comprehensive_snapshot(
                snapshot_data,
                "dashboard_run"
            )

            if snapshot_success:
                self.logger.info("ğŸ“¸ Snapshot completo salvo no banco")

            # âœ… MOSTRAR INFORMAÃ‡Ã•ES DO BANCO
            db_info = self.db_manager.get_database_info()
            if db_info:
                self.logger.info(f"ğŸ“Š Banco atualizado: {db_info['total_records']} registros totais")

            return True

        except Exception as e:
            self.logger.error(f"âŒ Erro ao salvar no banco: {e}")
            return False

    def display_dashboard(self, data, mining_metrics, profitability):
        """
        Exibe o dashboard no console
        """
        if not data:
            print("âŒ Nenhum dado para exibir")
            return

        collector_type = "MODULAR" if self.use_modular_collector else "DIRETO"
        db_status = "âœ… BANCO" if self.enable_database else "âŒ SEM BANCO"

        print("\n" + "="*80)
        print(f"ğŸ­ BITCOIN MINING ANALYTICS DASHBOARD [{collector_type}] [{db_status}]")
        print("="*80)
        print(f"ğŸ“… Ãšltima atualizaÃ§Ã£o: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ”— Fonte: {'Coletor Modular' if self.use_modular_collector else 'API Blockchair'}")
        print("="*80)

        # SeÃ§Ã£o: Rede Bitcoin
        print("\nğŸŒ REDE BITCOIN")
        print("-" * 40)
        print(f"âš¡  Hash Rate: {mining_metrics.get('hashrate_ehs', 0):.2f} EH/s")
        print(f"ğŸ—ï¸   Dificuldade: {data.get('difficulty', 0):,.0f}")
        print(f"ğŸ“¦  Blocos (24h): {data.get('blocks_24h', 0)}")
        print(f"ğŸ’°  PreÃ§o BTC: ${data.get('market_price_usd', 0):,.2f}")
        print(f"ğŸ“Š  TransaÃ§Ãµes (24h): {data.get('transactions_24h', 0):,}")
        print(f"ğŸ“¦  Mempool: {data.get('mempool_transactions', 0):,} tx")
        print(f"â±ï¸   Tempo mÃ©dio bloco: {mining_metrics.get('block_time_actual', 0):.1f}s")

        # SeÃ§Ã£o: MineraÃ§Ã£o
        print("\nâ›ï¸  MINERAÃ‡ÃƒO")
        print("-" * 40)
        print(f"ğŸ’¸  Hash Price: ${mining_metrics.get('hash_price_usd_per_th_per_day', 0):.4f}/TH/dia")
        print(f"ğŸ“ˆ  Receita diÃ¡ria rede: ${mining_metrics.get('daily_network_revenue_usd', 0):,.0f}")
        print(f"âš¡  Consumo energia estimado: {mining_metrics.get('estimated_daily_energy_consumption_gwh', 0):.1f} GWh/dia")

        # SeÃ§Ã£o: Lucratividade
        if profitability:
            print("\nğŸ’° LUCROTIVIDADE (S19 XP)")
            print("-" * 40)
            print(f"ğŸ’µ  Receita/dia: ${profitability.get('daily_revenue_usd', 0):.2f}")
            print(f"âš¡  Custo energia/dia: ${profitability.get('daily_energy_cost_usd', 0):.2f}")
            print(f"ğŸ“ˆ  Lucro/dia: ${profitability.get('daily_profit_usd', 0):.2f}")
            print(f"ğŸ“Š  Margem: {profitability.get('profit_margin_percentage', 0):.1f}%")
            print(f"ğŸ”„  ROI: {profitability.get('roi_days', 0):.0f} dias")

            status = "âœ… LUCRO" if profitability.get('daily_profit_usd', 0) > 0 else "âŒ PREJUÃZO"
            print(f"ğŸ¯  Status: {status}")

        # SeÃ§Ã£o: Taxas e Mempool
        print("\nğŸ’¸ TAXAS E MEMPOOL")
        print("-" * 40)
        print(f"ğŸ“¨  Taxa mÃ©dia: {data.get('average_transaction_fee_24h', 0)} sats")
        print(f"ğŸ’°  Taxa mÃ©dia (USD): ${data.get('average_transaction_fee_usd_24h', 0):.4f}")
        print(f"ğŸ”„  TPS: {data.get('mempool_tps', 0):.2f}")

        # SeÃ§Ã£o: AdoÃ§Ã£o e Nodes
        print("\nğŸŒ ADOÃ‡ÃƒO E REDE")
        print("-" * 40)
        print(f"ğŸ”—  Nodes: {data.get('nodes', 0):,}")
        print(f"ğŸ’¼  EndereÃ§os HODLing: {data.get('hodling_addresses', 0):,}")
        print(f"ğŸ’¾  Tamanho blockchain: {data.get('blockchain_size', 0) / 1e9:.1f} GB")

        print("\n" + "="*80)

    def save_data_backup(self, data):
        """
        Salva backup dos dados em JSON
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            collector_type = "modular" if self.use_modular_collector else "direct"
            filename = f"data/backups/blockchair_snapshot_{timestamp}_{collector_type}.json"

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            self.logger.info(f"âœ… Backup salvo: {filename}")
            print(f"âœ… Backup salvo: {filename}")
            return filename

        except Exception as e:
            self.logger.error(f"âŒ Erro ao salvar backup: {e}")
            print(f"âŒ Erro ao salvar backup: {e}")
            return None

    def save_analysis_report(self, data, mining_metrics, profitability):
        """
        Salva relatÃ³rio de anÃ¡lise
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            collector_type = "modular" if self.use_modular_collector else "direct"
            filename = f"results/financial_analysis/mining_analysis_{timestamp}_{collector_type}.json"

            report = {
                'timestamp': datetime.now().isoformat(),
                'data_source': 'blockchair',
                'collector_type': 'modular' if self.use_modular_collector else 'direct',
                'network_data': data,
                'mining_metrics': mining_metrics,
                'profitability_analysis': profitability
            }

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)

            self.logger.info(f"âœ… RelatÃ³rio de anÃ¡lise salvo: {filename}")
            print(f"âœ… RelatÃ³rio de anÃ¡lise salvo: {filename}")
            return filename

        except Exception as e:
            self.logger.error(f"âŒ Erro ao salvar relatÃ³rio: {e}")
            print(f"âŒ Erro ao salvar relatÃ³rio: {e}")
            return None

    def show_database_info(self):
        """Mostra informaÃ§Ãµes detalhadas do banco de dados"""
        if not self.enable_database or not self.db_manager:
            print("ğŸ—„ï¸  Banco de dados: Desativado")
            return

        try:
            db_info = self.db_manager.get_database_info()
            if db_info:
                print(f"\nğŸ—„ï¸  INFORMAÃ‡Ã•ES DO BANCO:")
                print(f"   ğŸ“ Arquivo: {db_info['database_path']}")
                print(f"   ğŸ’¾ Tamanho: {db_info['database_size_mb']} MB")
                print(f"   ğŸ“ˆ Total de registros: {db_info['total_records']}")

                if db_info['total_records'] > 0:
                    print(f"   â° PerÃ­odo: {db_info['oldest_record']} a {db_info['newest_record']}")

                print(f"   ğŸ“‹ Detalhes por tabela:")
                for table, count in db_info['record_counts'].items():
                    print(f"      ğŸ—ƒï¸  {table}: {count} registros")

                # Mostrar mÃ©tricas recentes do banco
                latest_metrics = self.db_manager.get_latest_metrics(1)
                if latest_metrics:
                    metric = latest_metrics[0]
                    print(f"   ğŸ“Š Ãšltima mÃ©trica:")
                    print(f"      ğŸ’° ${metric['price_usd']:,.0f} | âš¡ {metric['hashrate_ehs']:,.1f} EH/s")
        except Exception as e:
            self.logger.warning(f"âš ï¸ NÃ£o foi possÃ­vel obter informaÃ§Ãµes do banco: {e}")

    async def run_analysis(self):
        """
        Executa anÃ¡lise completa com DuckDB integrado
        """
        print("ğŸš€ INICIANDO ANÃLISE BITCOIN MINING ANALYTICS")
        print("=" * 60)

        if self.use_modular_collector:
            print("ğŸ”§ Modo: Coletor Modular")
        else:
            print("ğŸ”§ Modo: API Direta (Fallback)")

        if self.enable_database:
            print("ğŸ—„ï¸  PersistÃªncia: DuckDB Ativa")
        else:
            print("ğŸ—„ï¸  PersistÃªncia: Desativada")

        # Coletar dados
        data = await self.fetch_blockchain_data()

        if not data:
            print("âŒ Falha na coleta de dados. Verifique conexÃ£o e tente novamente.")
            return

        # Processar dados
        mining_metrics = self.calculate_mining_metrics(data)
        profitability = self.analyze_profitability(data, mining_metrics)

        # Exibir dashboard
        self.display_dashboard(data, mining_metrics, profitability)

        # Salvar dados
        backup_file = self.save_data_backup(data)
        report_file = self.save_analysis_report(data, mining_metrics, profitability)

        # âœ… SALVAR NO BANCO DE DADOS (AGORA FUNCIONAL)
        db_success = False
        if self.enable_database:
            db_success = self.save_to_database(data, mining_metrics, profitability)
        else:
            print("ğŸ“„ Dados salvos apenas em arquivos JSON")

        # Mostrar informaÃ§Ãµes do banco
        self.show_database_info()

        # Resumo final
        print("\nğŸ“Š RESUMO DA EXECUÃ‡ÃƒO:")
        print(f"âœ… Dados coletados: {len(data)} campos")
        print(f"âœ… MÃ©todo: {'Coletor Modular' if self.use_modular_collector else 'API Direta'}")

        if self.enable_database:
            if db_success:
                print("âœ… PersistÃªncia: Banco DuckDB (dados salvos)")
            else:
                print("âŒ PersistÃªncia: Banco DuckDB (falha no salvamento)")
        else:
            print("âœ… PersistÃªncia: Apenas arquivos JSON")

        if backup_file:
            print(f"âœ… Backup salvo: {backup_file}")
        if report_file:
            print(f"âœ… RelatÃ³rio salvo: {report_file}")

        print(f"âœ… Logs: logs/dashboard.log")

        print("\nğŸ¯ PRÃ“XIMOS PASSOS:")
        if self.enable_database and db_success:
            print("   ğŸ“Š Execute: python scripts/bitcoin_dashboard.py (para visualizar dados)")
            print("   ğŸ”„ Execute novamente para adicionar mais dados ao banco")
        else:
            print("   ğŸ”„ Execute novamente para dados atualizados")

        print("   ğŸ“ˆ Explore 'notebooks/01_data_collection/' para anÃ¡lises detalhadas")

        print("\n" + "="*60)
        print("âœ… ANÃLISE CONCLUÃDA COM SUCESSO!")

def main():
    """
    FunÃ§Ã£o principal para execuÃ§Ã£o do script
    """
    try:
        # Verificar se deve usar coletor modular
        use_modular = COLLECTOR_AVAILABLE
        enable_db = DB_AVAILABLE

        if not COLLECTOR_AVAILABLE:
            print("âš ï¸  Coletor modular nÃ£o disponÃ­vel, usando API direta")

        if not DB_AVAILABLE:
            print("âš ï¸  Banco DuckDB nÃ£o disponÃ­vel, usando apenas arquivos")

        dashboard = BitcoinBlockchairDashboard(
            use_modular_collector=use_modular,
            enable_database=enable_db
        )

        # Executar anÃ¡lise assÃ­ncrona
        asyncio.run(dashboard.run_analysis())

    except KeyboardInterrupt:
        print("\nâ¹ï¸  ExecuÃ§Ã£o interrompida pelo usuÃ¡rio")
    except Exception as e:
        print(f"âŒ Erro na execuÃ§Ã£o: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
